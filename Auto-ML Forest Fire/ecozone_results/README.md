# AutoML-ECOFIRE

### RESULTS

> Note:
> The current public release consolidates all core logic (training, modelling, reporting, GIS overlays, explainability, registry management, and prediction) into a **single integrated script** for reproducibility.
> A modular structure (`utils/`, `models/`, `pipelines/`) will be introduced in **v2**.
--

## ğŸ“Œ Full Results, Trained Models, and Analysis Dashboards

Due to GitHubâ€™s **100MB per-file limit**, trained models, geospatial overlays, reports, and results are hosted externally:

### ğŸ”— **Download Zone-wise Model Artefacts & Reports**
[https://drive.google.com/drive/folders/1Q8wu_sYGScowKygSP9utcJbm9B4AaXBd?usp=sharing](https://drive.google.com/drive/folders/1Q8wu_sYGScowKygSP9utcJbm9B4AaXBd?usp=sharing)

This archive contains:
* Trained models (.pkl) for every ecozone
* HTML zone assessment reports
* GIS wildfire risk heatmaps
* ROC curves and confusion matrices
* SHAP interpretability insights
* Feature ranking visualisations
* Global performance dashboards
* Registry metadata for inference

--

# ğŸ“¦ Results & Drive Folder Architecture

The model outputs and analysis reports are organised in the following structure (seen in Drive):

```
ecozone_results/
â”‚
â”œâ”€â”€ zone_0/
â”‚   â”œâ”€â”€ classifier.pkl
â”‚   â”œâ”€â”€ regressor.pkl
â”‚   â”œâ”€â”€ classifier_meta.json
â”‚   â”œâ”€â”€ regressor_meta.json
â”‚   â”œâ”€â”€ shap_summary_classifier.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ feature_importance_classifier.csv
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ zone_map.png
â”‚   â””â”€â”€ report.html
â”‚
â”œâ”€â”€ zone_1/
â”‚   â””â”€â”€ (same structure)
â”‚
â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ zone_11/               # final ecozone
â”‚
â”œâ”€â”€ global/
â”‚   â”œâ”€â”€ performance_summary.csv
â”‚   â”œâ”€â”€ global_confusion_matrix.png
â”‚   â”œâ”€â”€ spatial_performance_map.png
â”‚   â”œâ”€â”€ meta_correlation_matrix.png
â”‚   â””â”€â”€ index.html         # global dashboard
â”‚
â”œâ”€â”€ ecozone_knn.pkl        # ecozone routing model
â””â”€â”€ models_registry.pkl    # registry linking zones to estimators
```

This layout reflects a **geographically partitioned ML pipeline**, where models are optimised independently for each ecological zone.

---

---



## ğŸ“ Repository Structure (v1 Release)

```
project/
â”‚
â”œâ”€â”€ automl_adapted.py      # Single consolidated script: training, inference, GIS, reporting & explainability
â””â”€â”€ README.md
â””â”€â”€ Results
â””â”€â”€ Logs
â””â”€â”€ GEE Script to get dataset
```

> All pipeline stages and utilities are intentionally packaged together in v1 to simplify replication and review.

---

---

## ğŸ” System Objective

The project builds **operational wildfire intelligence** by:

* Detecting fire occurrence
* Estimating intensity
* Learning zone-specific behaviour
* Generating interpretable artefacts for planners
* Visualising risk surfaces spatially

Traditional one-model-fits-all approaches underperform in heterogeneous ecozones; this framework addresses that gap.

---

---

## âš™ï¸ Pipeline Overview

1. Dataset ingestion & ecozone assignment
2. Zone-wise preprocessing
3. Classifier and regressor selection via AutoML
4. Optuna tuning and metric optimisation
5. SHAP explainability and ranking
6. Zone-level reporting and HTML generation
7. GIS risk heatmaps and overlays
8. Global insight aggregation

---

---

## ğŸ§ª Execution (current version)

Training, explainability, dashboards, reporting, and GIS layers are executed entirely through:

```
automl_adapted.py
```

> Structured modules (`utils/`, `models/`, `geo/`, `reporting/`) are planned for **v2**.

---

## ğŸ“Œ Why are trained models stored externally?

GitHub enforces a **100MB per-file upper limit**.
Model artefacts, high-resolution maps, and results exceed this limit.

To maintain research accessibility:

âœ” Artefacts are hosted on Drive
âœ” Repository remains lightweight
âœ” Model versions can update without history rewrite

---

---

## ğŸ“¬ Future Release (v2 Roadmap)

* Separate modules for preprocessing, training, inference, GIS, and reporting
* Updated CLI interface (`main.py`)
* Deployment-ready predictor API wrapper
* Unit-tested reusable utilities
Agar chaho toh main **badge version**, **PDF one-pager**, ya **LinkedIn project summary** bhi bana deta ğŸ‘
